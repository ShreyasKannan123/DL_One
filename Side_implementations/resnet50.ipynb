{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_folder):\n",
    "    file_list = os.listdir(data_folder)\n",
    "    data = []\n",
    "    labels = []\n",
    "    for filename in file_list:\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        # Load audio file\n",
    "        audio, sr = librosa.load(filepath, sr=5500,mono=True)  # Adjust the sampling rate as needed\n",
    "        # Convert audio to spectrogram and resize\n",
    "        spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "        spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        \n",
    "        data.append(spectrogram)\n",
    "        labels.append(filename)\n",
    "    return data, labels\n",
    "\n",
    "# Function to define the model\n",
    "def define_model(num_classes):\n",
    "    resnet50 = models.resnet50(pretrained=False)\n",
    "    # Change the first convolutional layer to accept one input channel\n",
    "    resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "    num_features = resnet50.fc.in_features\n",
    "    resnet50.fc = nn.Linear(num_features, num_classes)\n",
    "    return resnet50\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs,save_path):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        num_batches = len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n",
    "        for i, (spectrograms, labels) in enumerate(train_loader, 1):\n",
    "            # spectrograms, labels = spectrograms, labels  # Move data to GPU if available\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(spectrograms)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % 10 == 0 or i == num_batches:\n",
    "                print(f\"  Batch {i}/{num_batches}, Loss: {loss.item():.4f}\")\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"  Epoch {epoch + 1} Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    print(f\"Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_spectrograms(spectrograms):\n",
    "    max_len = max(spec.shape[2] for spec in spectrograms)\n",
    "    padded_specs = []\n",
    "    for spec in spectrograms:\n",
    "        pad_len = max_len - spec.shape[2]\n",
    "        padded_spec = F.pad(spec, (0, pad_len))\n",
    "        padded_specs.append(padded_spec)\n",
    "    return padded_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "  Batch 1/1, Loss: 2.7173\n",
      "  Epoch 1 Loss: 0.2717\n",
      "Epoch 2/10:\n",
      "  Batch 1/1, Loss: 1.7097\n",
      "  Epoch 2 Loss: 0.1710\n",
      "Epoch 3/10:\n",
      "  Batch 1/1, Loss: 1.2118\n",
      "  Epoch 3 Loss: 0.1212\n",
      "Epoch 4/10:\n",
      "  Batch 1/1, Loss: 0.7438\n",
      "  Epoch 4 Loss: 0.0744\n",
      "Epoch 5/10:\n",
      "  Batch 1/1, Loss: 0.2260\n",
      "  Epoch 5 Loss: 0.0226\n",
      "Epoch 6/10:\n",
      "  Batch 1/1, Loss: 0.0658\n",
      "  Epoch 6 Loss: 0.0066\n",
      "Epoch 7/10:\n",
      "  Batch 1/1, Loss: 0.0137\n",
      "  Epoch 7 Loss: 0.0014\n",
      "Epoch 8/10:\n",
      "  Batch 1/1, Loss: 0.0065\n",
      "  Epoch 8 Loss: 0.0007\n",
      "Epoch 9/10:\n",
      "  Batch 1/1, Loss: 0.0039\n",
      "  Epoch 9 Loss: 0.0004\n",
      "Epoch 10/10:\n",
      "  Batch 1/1, Loss: 0.0027\n",
      "  Epoch 10 Loss: 0.0003\n",
      "Model saved to D:\\vs_code\\DL\\proj\\resources\\resnet_50_trained.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up dataset and dataloader\n",
    "data_folder = \"D:\\\\vs_code\\\\DL\\\\proj\\\\resources\\\\fma_small_edited_truncated\"\n",
    "data, labels = load_data(data_folder)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "tensor_data = [transform(spec) for spec in data]\n",
    "\n",
    "# Pad spectrograms\n",
    "padded_data = pad_spectrograms(tensor_data)\n",
    "\n",
    "# Extracting labels as tensors\n",
    "label_tensor = torch.tensor([int(label.split('.')[0]) for label in labels]) # Assuming filenames are like '0.mp3', '1.mp3', etc.\n",
    "\n",
    "\n",
    "dataset = list(zip(padded_data, label_tensor))  # Zip spectrograms and labels\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "num_classes = len(set(label_tensor))\n",
    "\n",
    "model = define_model(num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=10,save_path=\"D:\\\\vs_code\\\\DL\\\\proj\\\\resources\\\\resnet_50_trained.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
