{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4e067b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press Enter to start recording for 10 seconds...\n",
      "Press Enter to start recording:\n",
      "Recording finished.\n",
      "The closest match is: 000615 with a similarity score of 0.86\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def load_audio_files(directory):\n",
    "    audio_files = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mp3\") or filename.endswith(\".wav\"):\n",
    "            path = os.path.join(directory, filename)\n",
    "            audio_files.append(path)\n",
    "    return audio_files\n",
    "\n",
    "def audio_to_spectrogram(audio_path, max_pad_len=174):\n",
    "    y, sr = librosa.load(audio_path, duration=30)  # Load only the first 30 seconds\n",
    "    if len(y) < sr * 30:\n",
    "        y = np.pad(y, (0, max(sr * 30 - len(y), 0)), mode='constant')\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    if S_dB.shape[1] > max_pad_len:\n",
    "        S_dB = S_dB[:, :max_pad_len]\n",
    "    else:\n",
    "        S_dB = np.pad(S_dB, ((0, 0), (0, max_pad_len - S_dB.shape[1])), 'constant')\n",
    "    return S_dB\n",
    "\n",
    "def preprocess_spectrogram(S_dB):\n",
    "    S_dB = (S_dB - np.min(S_dB)) / (np.max(S_dB) - np.min(S_dB))\n",
    "    return S_dB.flatten()\n",
    "\n",
    "def load_and_preprocess_audio(directory):\n",
    "    audio_files = load_audio_files(directory)\n",
    "    labels = [os.path.splitext(os.path.basename(file))[0] for file in audio_files]\n",
    "    spectrograms = [audio_to_spectrogram(file) for file in audio_files]\n",
    "    preprocessed = [preprocess_spectrogram(spectrogram) for spectrogram in spectrograms]\n",
    "    return audio_files, labels, preprocessed\n",
    "\n",
    "def find_closest_match(input_spectrogram, training_spectrograms, labels):\n",
    "    input_preprocessed = preprocess_spectrogram(input_spectrogram)\n",
    "    similarities = cosine_similarity([input_preprocessed], training_spectrograms)\n",
    "    max_index = np.argmax(similarities)\n",
    "    return labels[max_index], similarities[0][max_index]\n",
    "\n",
    "def record_audio(duration=10, samplerate=22050):\n",
    "    print(\"Press Enter to start recording for {} seconds...\".format(duration))\n",
    "    input(\"Press Enter to start recording:\")  # User prompt to start recording\n",
    "    recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=2)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    output_filename = \"recording.wav\"\n",
    "    write(output_filename, samplerate, recording)  # Save as WAV file\n",
    "    print(\"Recording finished.\")\n",
    "    return output_filename\n",
    "\n",
    "# Main functionality\n",
    "def main():\n",
    "    training_directory = \"C:\\\\Users\\\\Plaksha\\\\Desktop\\\\Sem 6\\\\Deep Learning\\\\AALets do it viks\\\\Data\"\n",
    "    training_files, training_labels, training_spectrograms = load_and_preprocess_audio(training_directory)\n",
    "    \n",
    "    input_audio_path = record_audio()\n",
    "    input_spectrogram = audio_to_spectrogram(input_audio_path)\n",
    "    \n",
    "    closest_match_label, similarity_score = find_closest_match(input_spectrogram, training_spectrograms, training_labels)\n",
    "    print(f\"The closest match is: {closest_match_label} with a similarity score of {similarity_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5623454",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 18s 4s/step - loss: 178934176.0000 - accuracy: 0.0000e+00 - val_loss: 63380152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 29180164.0000 - accuracy: 0.0125 - val_loss: 17378088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 21306736.0000 - accuracy: 0.0125 - val_loss: 9786749.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 7586764.0000 - accuracy: 0.0125 - val_loss: 4590802.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 2113841.7500 - accuracy: 0.0250 - val_loss: 81422.3594 - val_accuracy: 0.0500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 34956.2773 - accuracy: 0.0500 - val_loss: 6955.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 2002.5068 - accuracy: 0.1125 - val_loss: 206.7642 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 19.3645 - accuracy: 0.1250 - val_loss: 83.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 9.6531 - accuracy: 0.1250 - val_loss: 38.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 5.9927 - accuracy: 0.1000 - val_loss: 16.7730 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.9837 - accuracy: 0.0750 - val_loss: 4.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 4.5427 - accuracy: 0.0250 - val_loss: 4.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.4846 - accuracy: 0.0250 - val_loss: 4.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5414 - accuracy: 0.0250 - val_loss: 4.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5407 - accuracy: 0.0250 - val_loss: 4.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5400 - accuracy: 0.0250 - val_loss: 4.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5393 - accuracy: 0.0250 - val_loss: 4.6412 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5386 - accuracy: 0.0250 - val_loss: 4.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5380 - accuracy: 0.0250 - val_loss: 4.6470 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5373 - accuracy: 0.0250 - val_loss: 4.6499 - val_accuracy: 0.0000e+00\n",
      "Press Enter to start recording for {} seconds...\n",
      "Press Enter to start recording:\n",
      "Recording finished.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Top Predicted Songs: ['001039', '001684', '000546']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import pandas as pd\n",
    "\n",
    "def load_audio_files(directory, duration=20, sr=22050):\n",
    "    labels = []\n",
    "    spectrograms = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mp3\") or filename.endswith(\".wav\"):\n",
    "            path = os.path.join(directory, filename)\n",
    "            audio, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "            audio = librosa.util.fix_length(audio, size=sr*duration)\n",
    "            S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "            S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "            spectrograms.append(S_dB)\n",
    "            labels.append(os.path.splitext(filename)[0])\n",
    "    return np.array(spectrograms), np.array(labels)\n",
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')  # Ensure softmax for multi-class classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  # Correct loss function\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def record_audio(filename='temp_recording.wav', duration=20, sr=22050):\n",
    "    print(\"Press Enter to start recording for {} seconds...\")\n",
    "    input(\"Press Enter to start recording:\")\n",
    "    recording = sd.rec(int(duration * sr), samplerate=sr, channels=2)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    write(filename, sr, recording)  # Save as WAV file\n",
    "    print(\"Recording finished.\")\n",
    "    return filename\n",
    "\n",
    "directory = \"C:\\\\Users\\\\Plaksha\\\\Desktop\\\\Sem 6\\\\Deep Learning\\\\AALets do it viks\\\\Data\"\n",
    "spectrograms, labels = load_audio_files(directory)\n",
    "labels, uniques = pd.factorize(labels)\n",
    "\n",
    "# Normalize spectrograms\n",
    "spectrograms = spectrograms / np.max(spectrograms)\n",
    "\n",
    "# Prepare data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms[..., np.newaxis], labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the CNN model\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(labels))\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "def predict_top_songs(audio_path, top_k=3):\n",
    "    audio, _ = librosa.load(audio_path, sr=22050, duration=20)\n",
    "    audio = librosa.util.fix_length(audio, size=22050*20)\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    S_dB = S_dB[np.newaxis, ..., np.newaxis] / np.max(S_dB)\n",
    "    predictions = model.predict(S_dB)\n",
    "    top_indices = np.argsort(predictions[0])[-top_k:][::-1]\n",
    "    return [uniques[i] for i in top_indices]\n",
    "\n",
    "# Record and predict\n",
    "input_audio_path = record_audio()\n",
    "top_songs = predict_top_songs(input_audio_path)\n",
    "print(\"Top Predicted Songs:\", top_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4878ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
