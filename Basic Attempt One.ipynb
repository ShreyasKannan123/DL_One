{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c4e067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44c89bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(directory, duration=20, sr=22050):\n",
    "    labels = []\n",
    "    spectrograms = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".mp3\") or filename.endswith(\".wav\"):\n",
    "            path = os.path.join(directory, filename)\n",
    "            audio, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "            audio = librosa.util.fix_length(audio, size=sr*duration)\n",
    "            S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=128)\n",
    "            S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "            spectrograms.append(S_dB)\n",
    "            labels.append(os.path.splitext(filename)[0])\n",
    "    return np.array(spectrograms), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')  # Ensure softmax for multi-class classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',  # Correct loss function\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5623454",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3/3 [==============================] - 18s 4s/step - loss: 178934176.0000 - accuracy: 0.0000e+00 - val_loss: 63380152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 29180164.0000 - accuracy: 0.0125 - val_loss: 17378088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 21306736.0000 - accuracy: 0.0125 - val_loss: 9786749.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 7586764.0000 - accuracy: 0.0125 - val_loss: 4590802.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 2113841.7500 - accuracy: 0.0250 - val_loss: 81422.3594 - val_accuracy: 0.0500\n",
      "Epoch 6/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 34956.2773 - accuracy: 0.0500 - val_loss: 6955.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 2002.5068 - accuracy: 0.1125 - val_loss: 206.7642 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 19.3645 - accuracy: 0.1250 - val_loss: 83.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "3/3 [==============================] - 11s 4s/step - loss: 9.6531 - accuracy: 0.1250 - val_loss: 38.8276 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 5.9927 - accuracy: 0.1000 - val_loss: 16.7730 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.9837 - accuracy: 0.0750 - val_loss: 4.6245 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "3/3 [==============================] - 13s 4s/step - loss: 4.5427 - accuracy: 0.0250 - val_loss: 4.6272 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.4846 - accuracy: 0.0250 - val_loss: 4.6300 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5414 - accuracy: 0.0250 - val_loss: 4.6328 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5407 - accuracy: 0.0250 - val_loss: 4.6356 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5400 - accuracy: 0.0250 - val_loss: 4.6384 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5393 - accuracy: 0.0250 - val_loss: 4.6412 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5386 - accuracy: 0.0250 - val_loss: 4.6441 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5380 - accuracy: 0.0250 - val_loss: 4.6470 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "3/3 [==============================] - 12s 4s/step - loss: 4.5373 - accuracy: 0.0250 - val_loss: 4.6499 - val_accuracy: 0.0000e+00\n",
      "Press Enter to start recording for {} seconds...\n",
      "Press Enter to start recording:\n",
      "Recording finished.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Top Predicted Songs: ['001039', '001684', '000546']\n"
     ]
    }
   ],
   "source": [
    "def record_audio(filename='temp_recording.wav', duration=20, sr=22050):\n",
    "    print(\"Press Enter to start recording for {} seconds...\")\n",
    "    input(\"Press Enter to start recording:\")\n",
    "    recording = sd.rec(int(duration * sr), samplerate=sr, channels=2)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    write(filename, sr, recording)  # Save as WAV file\n",
    "    print(\"Recording finished.\")\n",
    "    return filename\n",
    "\n",
    "directory = \"C:\\\\Users\\\\Plaksha\\\\Desktop\\\\Sem 6\\\\Deep Learning\\\\AALets do it viks\\\\Data\"\n",
    "spectrograms, labels = load_audio_files(directory)\n",
    "labels, uniques = pd.factorize(labels)\n",
    "\n",
    "# Normalize spectrograms\n",
    "spectrograms = spectrograms / np.max(spectrograms)\n",
    "\n",
    "# Prepare data for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrograms[..., np.newaxis], labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build and train the CNN model\n",
    "input_shape = X_train.shape[1:]\n",
    "num_classes = len(np.unique(labels))\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))\n",
    "\n",
    "def predict_top_songs(audio_path, top_k=3):\n",
    "    audio, _ = librosa.load(audio_path, sr=22050, duration=20)\n",
    "    audio = librosa.util.fix_length(audio, size=22050*20)\n",
    "    S = librosa.feature.melspectrogram(y=audio, sr=22050, n_mels=128)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    S_dB = S_dB[np.newaxis, ..., np.newaxis] / np.max(S_dB)\n",
    "    predictions = model.predict(S_dB)\n",
    "    top_indices = np.argsort(predictions[0])[-top_k:][::-1]\n",
    "    return [uniques[i] for i in top_indices]\n",
    "\n",
    "# Record and predict\n",
    "input_audio_path = record_audio()\n",
    "top_songs = predict_top_songs(input_audio_path)\n",
    "print(\"Top Predicted Songs:\", top_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4878ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
